# LSC_Astronophysics

# ğŸ“Œ Colombian Sign Language (LSC, in Spanish) Recognition Project for Astronomical Concepts

## ğŸ“– Introduction

**Colombian Sign Language (LSC)** is the natural language of the Deaf community in Colombia. It is a visual and gestural language with a unique grammatical structure, different from spoken or written Spanish. Its recognition and promotion are essential for the inclusion of deaf people in various fields, including education and scientific dissemination.

However, in the field of astronomy and space sciences, the availability of specific signs for technical terms is limited. This project seeks to address this gap by developing a **real-time sign recognition model** focused on key astronomical concepts.

---

## ğŸŒŸ Project Objective

Our main objective is to develop a system based on artificial intelligence that can recognize **10 astronomical terms** in Colombian Sign Language and translate them into text. This will facilitate access to scientific information for the deaf community and promote inclusion in education and scientific dissemination.

The terms included in this project are:

- ğŸŒ  **Asteroid**.
- ğŸ”­ **Astronomy**
- ğŸ’¥ **Big Bang**
- â˜„ï¸ **Cometa**
- ğŸŒ’ **Ecliptic**
- ğŸ›¤ï¸ **Celestial Equator**
- ğŸ”¥ **Meteorite**
- âœ¨ **Meteor**
- ğŸª **Metheoroid**
- â™’ **Zodiac**

---

## ğŸ› ï¸ Tools Used

For the implementation of this project, we used a combination of advanced tools in **computer vision and artificial intelligence**:

### ğŸ“Œ **MediaPipe**

[MediaPipe](https://developers.google.com/mediapipe) is a Google library specialized in **real-time image and video processing**. It allows us to detect **hands, face and body**, which is key to extract landmarks from the hands of users signing.

In this project, we use **MediaPipe Holistic**, which captures:
- ğŸ“Œ **21 landmarks of each hand**.

This data is converted into numerical vectors that feed our AI model.

### ğŸ¤– **LSTM Neural Network**.

We have implemented a **LSTM (Long Short-Term Memory)** type recurrent neural network in TensorFlow/Keras. This model is ideal for analyzing **sequences of data over time**, which is essential for gesture recognition in video.

#### ğŸ” **Model features**:
- ğŸ“Œ Processes **30-frame** sequences to recognize each gesture.
- ğŸ“Œ Learns spatial and temporal patterns in hand movements.
- ğŸ“Œ Generates a prediction with **one confidence probability** for each detected sign.

### ğŸ¥ **OpenCV**

To capture the webcam image and process it in real time, we use [OpenCV](https://opencv.org/), a computer vision library widely used in artificial intelligence projects.

---

## ğŸ—ï¸ Project Architecture

1ï¸âƒ£ **Video capture:** Live image is obtained from the camera.

2ï¸âƒ£ **Hand detection:** MediaPipe Holistic is used to extract hand landmarks.

3ï¸âƒ£ **Sequence processing:** 30-frame sequences of key points are stored.

4ï¸âƒ£ **Prediction with LSTM network:** The sequence is fed into the AI model, which predicts the realized sign.

5ï¸âƒ£ **Results visualization:** The detected sign with its confidence probability is displayed on the screen.

---

## ğŸ“¦ Installation and Execution

To run this project on your computer, follow these steps:

### Clone the repository
```bash
 git clone https://github.com/tonnysoyyo/LSC_Astronophysics.git
 cd LSC_Astronophysics
```

### Install dependencies
```bash
 pip install -r requirements.txt
```

### Execute real-time recognition
```bash
 python hands_process.py
```

### Execute Neural Network
```bash
 python LSTM_model.py
```

### Execute real-time test
```bash
 python real_time_test.py
```

---

## ğŸš€ Future of the Project.

This is just the beginning. In the future, we seek to:
- ğŸ”¹ **Expand the number of recognized signs**.
- ğŸ”¹ **Incorporate more precision in gesture recognition**.

We hope that this project will contribute to equitable access to astronomical knowledge for the deaf community. ğŸŒŒâœ¨

---

## ğŸ“ Credits.
This project has been developed by **[Diana Carolina Zapata and Tomas Sosa Giraldo]**, with the aim of promoting inclusion in science education and outreach. 

ğŸ“« **Contact:** 
[dianac.zapata@udea.edu.co]
[tomas.sosa@udea.edu.co]


# ğŸ“Œ Proyecto de Reconocimiento de Lengua de SeÃ±as Colombiana (LSC) para Conceptos AstronÃ³micos

## ğŸ“– IntroducciÃ³n

La **Lengua de SeÃ±as Colombiana (LSC)** es el idioma natural de la comunidad sorda en Colombia. Es una lengua visual y gestual con una estructura gramatical Ãºnica, diferente del espaÃ±ol hablado o escrito. Su reconocimiento y promociÃ³n son fundamentales para la inclusiÃ³n de las personas sordas en diversos Ã¡mbitos, incluyendo la educaciÃ³n y la divulgaciÃ³n cientÃ­fica.

Sin embargo, en el campo de la astronomÃ­a y las ciencias espaciales, la disponibilidad de seÃ±as especÃ­ficas para tÃ©rminos tÃ©cnicos es limitada. Este proyecto busca abordar esta brecha mediante el desarrollo de un **modelo de reconocimiento de seÃ±as en tiempo real**, centrado en conceptos astronÃ³micos clave.

---

## ğŸŒŸ Objetivo del Proyecto

Nuestro objetivo principal es desarrollar un sistema basado en inteligencia artificial que permita reconocer **10 tÃ©rminos astronÃ³micos** en Lengua de SeÃ±as Colombiana y los traduzca en texto. Esto facilitarÃ¡ el acceso a informaciÃ³n cientÃ­fica para la comunidad sorda y promoverÃ¡ la inclusiÃ³n en el Ã¡mbito educativo y de divulgaciÃ³n cientÃ­fica.

Los tÃ©rminos incluidos en este proyecto son:

- ğŸŒ  **Asteroide**
- ğŸ”­ **AstronomÃ­a**
- ğŸ’¥ **Big Bang**
- â˜„ï¸ **Cometa**
- ğŸŒ’ **EclÃ­ptica**
- ğŸ›¤ï¸ **Ecuador Celeste**
- ğŸ”¥ **Meteorito**
- âœ¨ **Meteoro**
- ğŸª **Meteoroide**
- â™’ **Zodiaco**

---

## ğŸ› ï¸ Herramientas Utilizadas

Para la implementaciÃ³n de este proyecto, hemos utilizado una combinaciÃ³n de herramientas avanzadas en **visiÃ³n por computadora e inteligencia artificial**:

### ğŸ“Œ **MediaPipe**

[MediaPipe](https://developers.google.com/mediapipe) es una biblioteca de Google especializada en **procesamiento de imÃ¡genes y video en tiempo real**. Nos permite detectar **manos, rostro y cuerpo**, lo cual es clave para extraer los puntos de referencia (landmarks) de las manos de los usuarios que realizan seÃ±as.

En este proyecto, utilizamos **MediaPipe Holistic**, que captura:
- ğŸ“Œ **21 puntos de referencia de cada mano**
- ğŸ“Œ **Pose corporal (aunque solo tomamos las manos)**
- ğŸ“Œ **Seguimiento en tiempo real con alta precisiÃ³n**

Estos datos son convertidos en vectores numÃ©ricos que alimentan nuestro modelo de IA.

### ğŸ¤– **Red Neuronal LSTM**

Hemos implementado una **red neuronal recurrente de tipo LSTM (Long Short-Term Memory)** en TensorFlow/Keras. Este modelo es ideal para analizar **secuencias de datos en el tiempo**, lo cual es esencial para el reconocimiento de gestos en video.

#### ğŸ” **CaracterÃ­sticas del modelo**:
- ğŸ“Œ Procesa secuencias de **30 fotogramas** para reconocer cada seÃ±a.
- ğŸ“Œ Aprende patrones espaciales y temporales en el movimiento de las manos.
- ğŸ“Œ Genera una predicciÃ³n con **una probabilidad de confianza** para cada seÃ±a detectada.

### ğŸ¥ **OpenCV**

Para capturar la imagen de la webcam y procesarla en tiempo real, usamos [OpenCV](https://opencv.org/), una biblioteca de visiÃ³n por computadora ampliamente utilizada en proyectos de inteligencia artificial.

---

## ğŸ—ï¸ Arquitectura del Proyecto

1ï¸âƒ£ **Captura de video:** Se obtiene la imagen en vivo desde la cÃ¡mara.

2ï¸âƒ£ **DetecciÃ³n de manos:** Se usa MediaPipe Holistic para extraer los puntos de referencia de las manos.

3ï¸âƒ£ **Procesamiento de secuencias:** Se almacenan secuencias de 30 frames de los puntos clave.

4ï¸âƒ£ **PredicciÃ³n con la red LSTM:** La secuencia se introduce en el modelo de IA, que predice el signo realizado.

5ï¸âƒ£ **VisualizaciÃ³n de resultados:** Se muestra en pantalla el signo detectado con su probabilidad de confianza.

---

## ğŸ“¦ InstalaciÃ³n y EjecuciÃ³n

Para ejecutar este proyecto en tu computadora, sigue estos pasos:

### 1ï¸âƒ£ Clonar el repositorio
```bash
 git clone https://github.com/tu_usuario/tu_repositorio.git
 cd tu_repositorio
```

### 2ï¸âƒ£ Instalar dependencias
```bash
 pip install -r requirements.txt
```

### 3ï¸âƒ£ Ejecutar el reconocimiento en tiempo real
```bash
 python reconocimiento_LSC.py
```

---

## ğŸš€ Futuro del Proyecto

Este es solo el inicio. En el futuro, buscamos:
- ğŸ”¹ **Ampliar el nÃºmero de seÃ±as reconocidas**.
- ğŸ”¹ **Incorporar mÃ¡s precisiÃ³n en el reconocimiento de gestos**.
- ğŸ”¹ **Optimizar el modelo para dispositivos mÃ³viles y web**.

Esperamos que este proyecto contribuya al acceso equitativo al conocimiento astronÃ³mico para la comunidad sorda. ğŸŒŒâœ¨

---

## ğŸ“ CrÃ©ditos
Este proyecto ha sido desarrollado por **[Tu Nombre/Equipo]**, con el objetivo de impulsar la inclusiÃ³n en la educaciÃ³n y divulgaciÃ³n cientÃ­fica. 

ğŸ“« **Contacto:** [tu.correo@example.com]

Neural Network to recognize the LSC in concepts of Astrophysics

Work in progress, based in the article: https://www.redalyc.org/journal/2570/257073797005/html/

By: Tomas Sosa Giraldo (tonnysoyyo) and Diana Carolina Zapata (dianaczapata27)